<!DOCTYPE html>
<html lang="he" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api/dist/face-api.js"></script>
    <style>
        body { margin: 0; background: #000; overflow: hidden; font-family: sans-serif; }
        canvas { position: absolute; left: 0; top: 0; width: 100vw; height: 100vh; object-fit: cover; }
        video { display: none; }
        #instruction { 
            position: absolute; top: 30px; width: 100%; text-align: center; 
            color: #fff; font-size: 24px; font-weight: bold; text-shadow: 2px 2px 4px #000; z-index: 100;
            transition: color 0.3s ease;
        }
        #ui { position: absolute; bottom: 20px; width: 100%; display: flex; flex-wrap: wrap; justify-content: center; gap: 10px; z-index: 100; padding: 10px; box-sizing: border-box; }
        button { padding: 12px 18px; border-radius: 20px; border: 2px solid #0f0; background: rgba(0,0,0,0.8); color: #0f0; font-weight: bold; }
        button.active { background: #0f0; color: #000; }
        #recBtn.recording { border-color: red; color: red; animation: blink 1s infinite; }
        @keyframes blink { 50% { opacity: 0.5; } }
    </style>
</head>
<body>
    <div id="instruction">1. ×’×¢ ×‘×œ×—×™×™× ×‘×¢×–×¨×ª ×©×ª×™ ×”×™×“×™×™×</div>
    <video id="video" playsinline autoplay muted></video>
    <canvas id="canvas"></canvas>
    <div id="ui">
        <button onclick="setMode('none')" id="btnNone" class="active">×¨×’×™×œ</button>
        <button onclick="setMode('left')" id="btnLeft">×©×××œ</button>
        <button onclick="setMode('right')" id="btnRight">×™××™×Ÿ</button>
        <button onclick="takeSnapshot()" style="border-color: white; color: white;">ğŸ“¸ ×ª××•× ×”</button>
        <button onclick="toggleRecording()" id="recBtn" style="border-color: #ff4444; color: #ff4444;">âº ×•×™×“××•</button>
    </div>

<script>
const video = document.getElementById('video');
const canvas = document.getElementById('canvas');
const ctx = canvas.getContext('2d');
const mainText = document.getElementById('instruction');
let mirrorMode = 'none';
let mediaRecorder;
let recordedChunks = [];
let isRecording = false;

async function setup() {
    await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
    await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/@vladmandic/face-api/model/');
    const stream = await navigator.mediaDevices.getUserMedia({ video: { facingMode: 'user' } });
    video.srcObject = stream;
    video.onloadedmetadata = () => {
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        detect();
    };
}

function setMode(mode) {
    mirrorMode = mode;
    document.querySelectorAll('#ui button').forEach(btn => btn.classList.remove('active'));
    document.getElementById('btn' + mode.charAt(0).toUpperCase() + mode.slice(1)).classList.add('active');
}

async function detect() {
    setInterval(async () => {
        const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks();
        ctx.clearRect(0, 0, canvas.width, canvas.height);

        if (detections.length > 0) {
            const landmarks = detections[0].landmarks;
            const nx = landmarks.getNose()[0].x;
            const vW = video.videoWidth;
            const vH = video.videoHeight;

            // ×‘×“×™×§×ª "× ×’×™×¢×”": ×× × ×§×•×“×•×ª ×§×•×•×™ ×”××ª××¨ ×©×œ ×”×œ×—×™×™× ××•×¡×ª×¨×•×ª
            // ×× ×—× ×• ×‘×•×“×§×™× ××ª ×”-Score ×©×œ × ×§×•×“×•×ª 0-16 (×§×• ×”×œ×¡×ª ×•×”×œ×—×™×™×)
            const jawPoints = landmarks.getJawOutline();
            const isTouching = jawPoints.some(pt => pt._x === undefined || pt._y === undefined); // ×‘××•×“×œ×™× ××¡×•×™××™×
            
            // ×©×™×˜×” ×—×œ×•×¤×™×ª: ×× ×”×¤× ×™× ××–×•×”×•×ª ××‘×œ ×”×™×“×™×™× ×‘×¤×¨×™×™×, ×”××¨×—×§ ×‘×™×Ÿ ×§×¦×•×•×ª ×”×¤× ×™× ××©×ª× ×”
            // ×œ×¦×¨×›×™ ×¤×©×˜×•×ª ×‘××™×™×¤×•×Ÿ, × ×©×ª××© ×‘×–×™×”×•×™ ×—×¡×™××” ×—×œ×§×™:
            if (detections[0].detection.score < 0.8) {
                mainText.innerText = "××¦×•×™×Ÿ!";
                mainText.style.color = "#0f0";
            } else {
                mainText.innerText = "1. ×’×¢ ×‘×œ×—×™×™× ×‘×¢×–×¨×ª ×©×ª×™ ×”×™×“×™×™×";
                mainText.style.color = "#fff";
            }

            if (mirrorMode === 'none') {
                ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
            } else if (mirrorMode === 'left') {
                ctx.drawImage(video, 0, 0, nx, vH, 0, 0, nx, vH);
                ctx.save(); ctx.translate(nx * 2, 0); ctx.scale(-1, 1);
                ctx.drawImage(video, 0, 0, nx, vH, 0, 0, nx, vH); ctx.restore();
            } else if (mirrorMode === 'right') {
                const rightPartW = vW - nx;
                ctx.drawImage(video, nx, 0, rightPartW, vH, nx, 0, rightPartW, vH);
                ctx.save(); ctx.translate(nx * 2, 0); ctx.scale(-1, 1);
                ctx.drawImage(video, nx, 0, rightPartW, vH, nx, 0, rightPartW, vH); ctx.restore();
            }
        } else {
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        }
    }, 40);
}

function takeSnapshot() {
    const link = document.createElement('a');
    link.download = 'capture.png';
    link.href = canvas.toDataURL('image/png');
    link.click();
}

function toggleRecording() {
    const recBtn = document.getElementById('recBtn');
    if (!isRecording) {
        recordedChunks = [];
        const stream = canvas.captureStream(30);
        mediaRecorder = new MediaRecorder(stream, { mimeType: 'video/webm' });
        mediaRecorder.ondataavailable = (e) => { if (e.data.size > 0) recordedChunks.push(e.data); };
        mediaRecorder.onstop = () => {
            const blob = new Blob(recordedChunks, { type: 'video/webm' });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a'); a.href = url; a.download = 'symmetry.webm'; a.click();
        };
        mediaRecorder.start();
        recBtn.classList.add('recording'); recBtn.innerText = 'â¹ ×¢×¦×•×¨'; isRecording = true;
    } else {
        mediaRecorder.stop(); recBtn.classList.remove('recording'); recBtn.innerText = 'âº ×•×™×“××•'; isRecording = false;
    }
}

document.body.addEventListener('click', () => video.play());
setup();
</script>
</body>
</html>
